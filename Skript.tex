\documentclass[a4paper]{article}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz,tkz-euclide}
\usepackage{titlesec}
\usepackage{gensymb}
\usepackage{textcomp}
\usepackage[titles]{tocloft}
\usepackage{csquotes}
\usepackage[babel]{microtype}
\usepackage{MnSymbol}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage[
  separate-uncertainty = true,
  multi-part-units = repeat
]{siunitx}

\usetkzobj{all}
\usetikzlibrary{shapes.misc}

\MakeOuterQuote{"}

\newcommand*\circled[1]{
  \tikz[baseline=(C.base)]\node[draw,circle,inner sep=0.75pt](C) {#1};\!
}

\newcommand*{\obot}{\perp\mkern-20.7mu\bigcirc}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

\renewcommand{\thesubsection}{\arabic{subsection}}
\titleformat{\section}{\normalfont\Large\bfseries}{Kapitel \arabic{section}: }{0em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{§\arabic{subsection} }{0em}{}
\titleformat{\subsubsection}{\normalfont\bfseries}{\arabic{subsection}.\arabic{subsubsection} }{0em}{}
\renewcommand{\cftsubsecpresnum}{§}
\newlength\mylength
\settowidth\mylength{\cftsubsecpresnum}
\settowidth\mylength{\cftsubsecaftersnum}
\addtolength\cftsubsecnumwidth{\mylength}
\renewcommand{\cftsecpresnum}{Kapitel }
\renewcommand{\cftsecaftersnum}{: }
\settowidth\mylength{\cftsecpresnum}
\addtolength\cftsecnumwidth{\mylength}

\newcommand{\ul}{\underline}
\renewcommand{\proof}{\ul{Beweis:}\\}
\renewcommand{\qed}{\begin{flushright}
\ul{\(q.e.d.\)}
\end{flushright}}
\let\origphi\phi
\let\phi\varphi
\let\origepsilon\epsilon
\let\epsilon\varepsilon

\title{Lineare Algebra II: Skript}
\author{Nico Mexis}
\date{\today}

\begin{document}
\maketitle
\newpage

\tableofcontents
\newpage

\setcounter{section}{4}
\section{Endomorphismen}
\setcounter{subsection}{17}
\subsection{Eigenwerte (Buch: §4.1-4.2)}
Sei \(K\) ein Körper.\\
Sei \(V\) ein endlich dimensionaler \(K\)-Vektorraum.\\
Sei \(\phi: V \rightarrow V\) ein Endomorphismus.
\subsubsection{Definition}
\begin{itemize}
\item[\circled{a}] Ein Element \(\lambda \in K\) heißt ein \ul{Eigenwert} von \(\phi\), wenn es einen Vektor \(v \in V\ \backslash \{0\}\) gibt mit \(\phi(v)=\lambda*v\).
\item[\circled{b}] Ist \(\lambda \in K\) ein Eigenwert von \(\phi\), so heißt jeder Vektor \(v \in V \backslash \{0\}\) mit \(\phi(v) = \lambda*v\) ein Eigenvektor von \(\phi\) zum Eigenwert \(\lambda\).
\item[\circled{c}] Ist \(A \in Mat_n(K)\), so heißt ein \(\lambda \in K\) ein \ul{Eigenwert} von A, wenn es ein \(v \in K^n\backslash\{0\}\) gibt mit \(A*v=\lambda*v\).
\end{itemize}
\subsubsection{Beispiel}
\begin{itemize}
\item[\circled{a}] Das Element \(0 \in K\) ist ein Eigenwert von \(\phi\), wenn \(\phi\) nicht injektiv ist.
\item[\circled{b}] Das Element \(1 \in K\) ist ein Eigenwert von \(\phi\), wenn \(\phi\) einen \ul{Fixpunkt} \(v \neq 0\) hat (d.h. \(\phi(v)=v\)).
\end{itemize}
\subsubsection{Beispiel}
Sei \(K = \mathbb{R}, V= \mathbb{R}^2\).\\
Sei \(\phi:\mathbb{R}^2\rightarrow\mathbb{R}^2\) die Drehung um \(0=(0,0)\) um den Winkel \(\alpha \in [0,2\pi[\).\\
\begin{itemize}
\item[\circled{a}] Ist \(\alpha = 0\), so ist \(\phi = id_{\mathbb{R}^2}\) und \(\lambda = 1\) ist der einzige Eigenwert von \(\phi\).
\item[\circled{b}] Ist \(\alpha = \pi\), so ist \(\phi = -id_{\mathbb{R}^2}\) und \(\lambda = -1\) ist der einzige Eigenwert von \(\phi\).
\item[\circled{c}] Ist \(\alpha \notin \{0,\pi\}\), so besitzt \(\phi\) keine Eigenwerte.
\end{itemize}
\subsubsection{Beispiel}
Sei \(K = \mathbb{R}, V= \mathbb{R}^2\) und \(\sigma :\mathbb{R}^2 \rightarrow\mathbb{R}^2\) die Spiegelung an der Geraden \(G\) durch \(0\), die mit der x-Achse einen Winkel \(\frac{\alpha}{2}\) einschließt.
Ein Eigenwert ist \(\lambda=1\) und die Menge der Eigenvektoren zum Eigenwert \(\lambda=1\) ist \(G\backslash\{0\}\).\\
Ein weiterer Eigenwert ist \(\lambda=-1\) und die Menge der Eigenvektoren zum Eigenwert \(\lambda=-1\) ist \(H\backslash\{0\}\), wobei \(H\) die zu \(G\) senkrechte Gerade durch 0 ist.
\subsubsection{Definition}
Sei \(\lambda \in K\) ein Eigenwert von \(\phi\). Dann heißt \(Eig(\phi,\lambda)=\{v \in V | \phi (v)=\lambda *v\}\) der \ul{Eigenraum} zum Eigenwert \(\phi\).
\subsubsection{Satz}
Sei \(\phi:V \rightarrow V\) ein Endomorphismus.
\begin{itemize}
\item[\circled{a}] Ist \(\lambda \in K\) ein Eigenwert von \(\phi\), so ist \(Eig(\phi,\lambda)\) ein Untervektorraum von V.
\item[\circled{b}] Sind \(\lambda,\mu \in K\) zwei verschiedene Eigenwerte von \(\phi\), so gilt: \(Eig(\phi,\mu)=\{0\}\).
\end{itemize}
\newpage
\ul{Beweis:}
\begin{itemize}
\item["\circled{a}"] Wegen \(\phi(0)=\lambda*0=0\) gilt \(\phi(v-w)=\phi(v)-\phi(w)=\lambda*v-\lambda*w=\lambda*(v-w)\), also \(v-w \in Eig(\phi,\lambda)\). Nach dem Untervektorraumkriterium folgt die Behauptung.
\item["\circled{b}"] Sei \(v \in Eig(\phi,\lambda)\cap Eig(\phi,\mu)\). Dann gilt \(\lambda*v=\phi(v)=\mu*v\), also \(\underbrace{(\lambda-\mu)}_{\neq 0}*v=0\). Dies liefert \(v=0\).
\end{itemize}
\qed
\subsubsection{Beispiel}
\begin{itemize}
\item[\circled{a}] Sei \(K = \mathbb{R}\), \(V = \mathbb{R}^2\) und \(\phi:\mathbb{R}^2\rightarrow \mathbb{R}^2\) die Spiegelung an der Winkelhalbierenden. Dann gilt \(M_{\xi}^{\xi}(\phi)=\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}\) und die Eigenwerte von \(\phi\) sind \(\lambda = \pm 1\)
\begin{itemize}
\item[\circled{1}] \(Eig(\phi,1)=\mathbb{R}*(1,1)\)
\item[\circled{2}] \(Eig(\phi,-1)=\mathbb{R}*(1,-1)\)
\end{itemize}
\item[\circled{b}] Sei \(K = \mathbb{R}\), \(V = \mathbb{R}^3\) und \(\phi:\mathbb{R}^3\rightarrow \mathbb{R}^3\) die Drehung um die z-Achse um einen Winkel \(\alpha \in ]0,\pi[\). Dann gilt \(M_{\xi}^{\xi}(\phi)=\begin{pmatrix}
cos(\alpha) & -sin(\alpha) & 0 \\
sin(\alpha) & cos(\alpha) & 0 \\
0 & 0 & 1
\end{pmatrix}\) und \(\lambda = 1\) ist der einzige Eigenwert mit \(Eig(\phi,1)=\mathbb{R}*\underbrace{(0,0,1)}_{z-Achse}\).
\end{itemize}
\subsubsection{Definition}
\begin{itemize}
\item[\circled{a}] Der Endomorphismus \(\phi:V\rightarrow V\) heißt \ul{diagonalisierbar}, wenn es eine Basis \(B\neq (v_1,\dots,v_d)\) von \(V\) gibt, die aus Eigenvektoren besteht.\\
Sei \(\phi(v_i)=a_iv_i\) mit \(a_i \in K\) für \(i=1,..,d\). Dann gilt also \(M^B_B(\phi)=\begin{pmatrix}
a_1 & 0 & \hdots & 0 \\
0 & a_2 & \hdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \hdots & a_n
\end{pmatrix}\) Diagonalmatrix.
\item[\circled{b}] Eine Matrix \(A \in Mat_n(K)\) heißt \ul{diagonalisierbar}, wenn der zugehörige Endomorphismus \(\phi_A:K^n\rightarrow K^n\) diagonalisierbar ist, d.h. wenn es ein \(T \in GL_n(K)\) gibt, sodass \(TAT^{-1}\) eine Diagonalmatrix ist.
\end{itemize}
\subsubsection{Satz (Charakterisierung der Diagonalisierbarkeit)}
Für einen Endomorphismus \(\phi:V\rightarrow V\) sind die folgenden Bedingungen äquivalent:
\begin{itemize}
\item[\circled{a}] \(\phi\) ist diagonalisierbar.
\item[\circled{b}] Es gibt eine Basis \(B\) von \(V\), sodass \(M_B^B(\phi)\) eine Diagonalmatrix ist.
\item[\circled{c}] Für jede Basis \(B\) von \(V\) ist \(M_B^B(\phi)\) eine diagonalisierbare Matrix.
\item[\circled{d}] Es gibt eine Basis \(B\) von \(V\), die aus Eigenvektoren von \(\phi\) besteht.
\end{itemize}
\ul{Beweis:}
\begin{itemize}
\item["\circled{a} \textrightarrow \space\circled{b}"] Def. 18.8a
\item["\circled{b} \textrightarrow \space\circled{c}"] Sei \(B\) eine Basis von \(V\), sodass \(M_B^B(\phi)\) eine Diagonalmatrix ist und sei \(C\) eine weitere Basis von \(V\). Dann gilt: \(M_B^B(\phi)=T_C^B*M_C^C(\phi)*(T_C^B)^{-1}\) mit \(T_C^B\in GL_n(K)\). Also ist \(M_C^C(\phi)\) diagonalisierbar.
\item["\circled{c} \textrightarrow \space\circled{d}"] Nach Def. 18.8b gibt es \(T \in GL_n(K)\) mit \(T*M_C^C(\phi)*T^{-1}\) Diagonalmatrix. Bzgl. der transponierten Basis \(B=T*C\) ist also \(M_B^B(\phi)\) eine Diagonalmatrix, d.h. \(B\) besteht aus Eigenvektoren von \(\phi\).
\item["\circled{d} \textrightarrow \space\circled{a}"] Nach Def.
\end{itemize}
\qed
\subsubsection{Beispiel}
Eigenwerte und Eigenvektoren spielen eine große Rolle beim Lösen von \ul{Differentialgleichungen}.\\
Suche z.B. im \(\mathcal{C}^1(\mathbb{R})\) die Lösungen von\\
\(f_1'(t)=f_1(t)-f_2(t)\)\\
\(f_2'(t)=2f_1(t)+4f_2(t)\).\\
Man macht folgenden Lösungsansatz: \(f_1(t)=c_1*e^{\lambda t}\) und \(f_2(t)=c_2*e^{\lambda t}\)\\
\(\Rightarrow \begin{pmatrix}
f_1'(t) \\
f_2'(t)
\end{pmatrix} = \begin{pmatrix}
\lambda c_1e^{\lambda t} \\
\lambda c_2e^{\lambda t}
\end{pmatrix} = \lambda * \begin{pmatrix}
f_1(t) \\
f_2(t)
\end{pmatrix}\).\\
Das Differentialgleichungssystem lautet also:\\
\(\begin{pmatrix}
f_1'(t) \\
f_2'(t)
\end{pmatrix} = \lambda * \begin{pmatrix}
f_1(t) \\
f_2(t)
\end{pmatrix} = \begin{pmatrix}
1 & -1 \\
2 & 4
\end{pmatrix} * \begin{pmatrix}
f_1(t) \\
f_2(t)
\end{pmatrix}\).\\
Im \(\mathbb{R}\)-Vektorraum \(\mathcal{C}^1(\mathbb{R})\) ist \(\begin{pmatrix}
f_1'(t) \\
f_2'(t)
\end{pmatrix}\) ein Eigenvektor der Matrix \(\begin{pmatrix}
1 & -1 \\
2 & 4
\end{pmatrix}\) zum Eigenwert \(\lambda\).
\subsubsection{Satz}
Ist \(\lambda \in K\) ein Eigenwert von \(\phi\), so gilt: \(Eig(\phi, \lambda)=Ker(\phi-\lambda*id_V)\).\\
\ul{Beweis:}\\
Es gilt \(v \in Eig(\phi, \lambda) \Leftrightarrow \phi(v)=\lambda *v \Leftrightarrow(\phi-\lambda*id_V)(v)=0 \Leftrightarrow v\in Ker(\phi-v*id_V)\).
\qed
\subsubsection{Definition}
Sei \(x\) eine Unbestimmte und \(\mathcal{A} = (a_{ij}) \in Mat_n(K)\). Dann gilt: \(\mathcal{A}-x*\mathcal{I}_n=\begin{pmatrix}
a_{11}-x & a_{12} & \hdots & a_{1n} \\
a_{21} & a_{22}-x & \hdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \hdots & a_{nn}-x
\end{pmatrix} \in Mat_n(K[x])\).\\
Dann heißt \(det(\mathcal{A}-x*\mathcal{I}_n)\in K[x]\) das \ul{charakteristische Polynom} von \(\mathcal{A}\) und wird mit \(\underset{"chi"}{\chi_A}(x)\) bezeichnet.
\subsubsection{Beispiel}
Sei \(\mathcal{A}=\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix} \in Mat_2(\mathbb{Q})\). Dann gilt \(\chi_A(x)=det\begin{pmatrix}
-x & 1 \\
1 & -x
\end{pmatrix}=x^2-1\).
\subsubsection{Satz}
Seien \(B,C\) zwei Basen von \(V\). Dann gilt:\\
\(\chi_{M_B^B(\phi)}(x)=\chi_{M_C^C(\phi)}(x)\)\\
\ul{Beweis:}\\
Nach der Transformationsformel gilt:\\
\(M_C^C(\phi)=T_C^B*M_B^B(\phi)*T_B^C\)\\
Es folgt: \(\chi_{M_C^C(\phi)}(x)=det(T_C^BM_B^B(\phi)T_B^C-\underbrace{T_C^Bx\mathcal{I}_nT_B^C}_{=x\mathcal{I}_n})\\=det(T_C^B(M_B^B(\phi)-x\mathcal{I}_n)T_B^C)\\=det(T_C^B)*det(M_B^B(\phi)-x*\mathcal{I}_n)*det(T_C^B)^{-1}=\chi_{M_B^B(\phi)}(x)\).
\qed
\ul{Folgerung:} Das Polynom \(\chi_{M_B^B(\phi)}(x)\) hängt nur von \(\phi\), aber nicht von der Wahl der Basis \(B\) ab. Es heißt das \ul{charakteristische Polynom} von \(\phi\) und wird mit \(\chi_\phi(x)\) bezeichnet.
\subsubsection{Satz}
Ein Element \(\lambda \in K\) ist genau dann ein Eigenwert von \(\phi\), wenn \(\chi_{\phi}(\lambda)=0\) gilt.\\
\ul{Beweis:}\\
Genau dann ist \(\lambda \in K\) ein Eigenwert von \(\phi\), wenn \(Ker(\phi-\lambda id_V)\neq \{0\}\) gilt. Dies ist genau dann der Fall, wenn \(\phi-\lambda id_V\) nicht bijektiv ist. Letztere Bedingung ist äquivalent zu \(det(\phi-\lambda id_V)=0\), also zu \(\chi_\phi(\lambda)=0\).
\qed
\subsubsection{Beispiel}
\begin{itemize}
\item[\circled{a}] Sei \(\phi:\mathbb{R}^2\rightarrow\mathbb{R}^2\) die Spiegelung an der Winkelhalbierenden \(G=\mathbb{R}*\begin{pmatrix}
1 \\
1
\end{pmatrix}\). Dann gilt: \(M_\xi^\xi(\phi)=\begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}\) und  \(\chi_\phi(x)=x^2-1=(x-1)(x+1)\). Also besitzt \(\phi\) zwei Eigenwerte, nämlich \(\lambda_1=1\) und \(\lambda_2=-1\).\\
Für \(\lambda_1=1\) gilt \(Eig(\phi,\lambda_1)=Ker(\phi-\lambda_1 id_{\mathbb{R}^2})=Ker\begin{pmatrix}
-1 & 1 \\
1 & -1
\end{pmatrix} = \\<\begin{pmatrix}
1 \\
1
\end{pmatrix}> = G\).\\
Für \(\lambda_2=-1\) gilt \(Eig(\phi,\lambda_2)=Ker(\phi-\lambda_2 id_{\mathbb{R}^2})=Ker\begin{pmatrix}
1 & 1 \\
1 & 1
\end{pmatrix} = \\<\begin{pmatrix}
-1 \\
1
\end{pmatrix}> = G^\bot\).
\item[\circled{b}] Sei \(\psi:\mathbb{R}^2\rightarrow\mathbb{R}^2\) die Drehung um \(0\) um den Winkel \(\alpha \in ]0,\pi[\). Dann gilt \(M_\xi^\xi(\psi)=\begin{pmatrix}
cos(\alpha) & -sin(\alpha) \\
sin(\alpha) & cos(\alpha)
\end{pmatrix}\).\\
\(\chi_\psi(x)=det\begin{pmatrix}
cos(\alpha)-x & -sin(\alpha) \\
sin(\alpha) & cos(\alpha)-x
\end{pmatrix}=(cos(\alpha)-x)^2+sin^2(\alpha)=x^2-2cos(\alpha)x+sin^2(\alpha)+cos^2(\alpha)=x^2-2cos(\alpha)x+1\).\\
Dieses quadratische Polynom hat die Diskriminante \(\triangle=4cos^2(\alpha)-4=-4sin^2(\alpha)<0\). Somit besitzt \(\psi\) keine Eigenwerte.
\end{itemize}
\subsubsection{Bemerkung}
Ein Polynom \(f \in K[x]\backslash K\) braucht keine Nullstelle in \(K\) zu besitzen (z.B. \(x^2+1 \in \mathbb{R}[x])\).\\
Der \ul{Fundamentalsatz der Algebra} besagt, dass jedes Polynom \(f \in \mathbb{C} [x] \backslash \mathbb{C}\) eine Nullstelle besitzt und somit in ein Produkt von Linearfaktoren zerfällt.
\subsubsection{Satz (Eigenschaften des charakteristischen Polynoms)}
Sei \(\phi:V\rightarrow V\ K\)-linear und \(n=dim_K(V)\). Dann gilt:
\begin{itemize}
\item[\circled{a}] \(deg(\chi_\phi(x))=n\).
\item[\circled{b}] Der Gradkoeffizient von \(\chi_\phi(x)\) ist \((-1)^n\), also \(\chi_\phi(x)=(-1)^nx^n+(Monome\ kleineren\ Grades)\)
\item[\circled{c}] Der konstante Term von \(\chi_\phi(x)\) ist \(det(\phi)=\chi_\phi(0)\).
\end{itemize}
\ul{Beweis:}\\
\begin{itemize}
\item["\circled{a},\circled{b}"] Sei \(\mathcal{A}=(a_{ij})\in Mat_n(K)\) eine Darstellungsmatrix von \(\phi\). Dann gilt \(\chi_\phi(x)=det\begin{pmatrix}
a_{11}-x & & * \\
 & \ddots & \\
 * & & a_{nn}-x
\end{pmatrix}=(a_{11}-x)(a_{22}-x)*\dots*(a_{nn}-x)+(Monome\ niedriegeren\ Grades\ als\ n)=(-x)^n+(Monome\ niedriegeren\ Grades\ als\ n)\)
\item["\circled{c}"] \(\chi_\phi(0)=det(\phi-0*id_V)=det(\phi)\).
\end{itemize}
\qed
\subsubsection{Bemerkung (Der zweite Koeffizient von \(\chi_\phi(x)\))}
Schreibe \(\chi_\phi(x)=(-1)^nx^n+c_{n-1}x^{n-1}+\dots+c_1x+c_0\). Dann heißt \(Spur(\phi)=\underset{"Trace"}{Tr}(\phi)=(-1)^{n-1}c_{n-1}\) die \ul{Spur} von \(\phi\).\\
Sie hängt nicht ab von der Wahl einer Darstellungsmatrix \(\mathcal{A}=(a_{ij})\). Es gilt \(Spur(\mathcal{A})=a_{11}+a_{22}+\dots+a_{nn}\).\\
\ul{Beweis:}\\
Um einen Summanden \(c*x^{n-1}\) in \(det\begin{pmatrix}
a_{11}-x & & & * \\
 & a_{22}-x & & \\
 & & \ddots & \\
* & & & a_{nn}-x
\end{pmatrix}\) zu erhalten, muss man genau \(n-1\)mal den Faktor \(a_{ii}-x\) wählen. Also suchen wir den Koeffizienten von \(x^{n-1}\) in \((a_{11}-x)*\dots*(a_{nn}-x)\). Beim Ausmultiplizieren muss man \((n-1)\)mal \(-x\) wählen und einmal \(a_{ii}\). Also gilt \(c=(-1)^{n-1}(a_{11}+a_{22}+\dots+a_{nn})=(-1)^{n-1} Spur(\phi)\).
\qed
HIER FEHLT VIEL
\setcounter{subsection}{21}
\subsection{Verallgemeinerte Eigenräume}
Sei \(K\) Körper, \(V\) endlich-dimensionaler \(K\)-Vektorraum, \(\phi \in End_K(V)\)\\
\(\chi_\phi(v)=det(\phi-x\cdot id_V)\) charakteristisches Polynom\\
\(\mu_\phi(x)=\) normiertes Polynom kleinsten Grades mit \(\mu_\phi (\phi) = 0 \hat{=}\) Minimalpolynom von \(\phi\).
\subsubsection{Definition (Großer Kern und kleines Bild)}
(a) Die Kette \(Ker(\phi) \subseteq Ker(\phi^2) \subseteq Ker(\phi^3) \subseteq \dots\) von \(K\)-Untervektorräumen von \(V\) wird stationär. Der Untervektorraum \(BigKer(\phi)=Ker(\phi^i)\) mit \(i >> 0\) heißt der \ul{große Kern} von \(\phi\).
(b) Die Kette \(Im(\phi) \supseteq Im(\phi^2) \supseteq \dots\) wird stationär. Der Untervektorraum \(SmIm(\phi) = Im(\phi^i)\) mit \(i >> 0\) heißt das \ul{kleine Bild} von \(\phi\).
\subsubsection{Satz (Das Lemma von Fitting)}
(a) Gilt \(Ker(\phi^m)=Ker(\phi^{m+1})\) für ein \(m \geq 1\), so gilt \(Ker(\phi^m)=Ker(\phi^i)\) für alle \(i \geq m\) und somit \(BigKer(\phi)=Ker(\phi^m)\).
(b) Gilt \(Im(\phi^{m'})=Im(\phi^{m'+1})\) für ein \(m' \geq 1\), so folgt \(Im(\phi^{m'})=Im(\phi^i)\) für alle \(i \geq m'\) und somit \(SmIm(\phi)=Im(\phi^{m'})\).
(c) Sind \(m,m'\) in (a) und (b) minimal, so folgt \(m=m'\).
(d) Die Ketten \({0} \subseteq Ker(\phi) \subsetneq Ker(\phi^2) \subsetneq \dots \subsetneq Ker(\phi^m)=BigKer(\phi)\) und \(V \supseteq Im(\phi) \supsetneq Im(\phi^2) \supsetneq \dots \supsetneq Im(\phi^{m'}) = SmIm(\phi)\) enthalten strikte Inklusionen.
(e) \fbox{\(V=BigKer(\phi) \oplus SmIm(\phi)\)}
\ul{Beweis:}\\
"a" Es genügt \(Ker(\phi^{m+1}) =Ker(\phi^{m+2})\) zu beweisen. Zeige "\(\supseteq\)".Sei \(v \in Ker(\phi^{m+2})\), also \(\phi^{m+1}(v)=0\), so folgt \(\phi(v)\in Ker(\phi^{m+1})=Ker(\phi^m)\), also \(\phi^{m+1}(v)= \phi^m(\phi(v))=0\) und somit \(v \in Ker(\phi^{m+1})\).
"b" Zu zeigen ist nur \(Im(\phi^{m+1}) \subseteq Im(\phi^{m+2})\). Dazu sei \(v\in Im(\phi^{m+1})\), also \(v=\phi^{m+1}(w)\) mit \(w\in V\). Dann folgt \(v=\phi(\overset{~}{v})\) mit \(\overset{~}{v} = \phi^m(w)\in I(\phi^m)=Im(\phi^{m+1})\). Somit gilt \(v~ = \phi^{m+1}(w~)\) mit \(w~ \in V\) und \(v=\phi(v~)=\phi^{m+1}(w~)\in Im(\phi^{m+1})\).
"c" Es gilt \(dim_K(V)=dim_K(Ker(\phi^m))+dim_K(Im(\phi^m))\) und \(dim_K(V)=dim_K(Ker(\phi^{m+1})+dim_K(Im(\phi^{m+1})\).
Aus \(Ker(\phi^m)=Ker(\phi^{m+1})\) folgt damit \(dim_K(Im(\phi^m))=dim_K(\phi^{m+1})\) und daher \(Im(\phi^m)=Im(\phi1{m+1})\).
"d" folgt aus (a) und (b).
"e" Nach (c) gilt \(dim_K(V)=dim_K(Ker(\phi^m))+dim_K(Im(\phi^m))\) für das minimale \(m\). (Insbesondere gilt: \(BigKer(\phi)=Ker(\phi^m)\) und \(SmIm(\phi)=Im(\phi^m)\) für dieses \(m\)).\\
Zu zeigen ist also \(Ker(\phi^m) \cap Im(\phi^m)={0}\).\\
Sei \(v = \phi^m(w)\in Ker(\phi^m)\) für ein \(w\in V\). Dann gilt \(\phi^m(v)=\phi^{2m}(w)=0\), also \(w\in Ker(\phi^{2m})=Ker(\phi^m)\) und somit \(v=\phi^m(w)=0\).
\qed
\ul{Wdh.:}\\
Sei \(\lambda\in K\) ein Eigenwert von \(\phi\). Dann ist \(x-\lambda\) ein Eigenfaktor und \(Eig(\phi, \lambda)=Ker(\phi-\lambda\cdot id_V)={v\in V | \phi(v)=\lambda v}\).
\subsubsection{Definition}
Sei \(\phi\in End_K(V)\) und \(\mu_\phi(x)^m_1\dots p_s(x)^{m_s}\) mit den Eigenfaktoren \(p_1(x),\dots,p_s(x)\) und mit \(m_i\geq 1\).
(a) der \(K\)-Untervektorraum \(Eig(\phi, p_i(x)) = Ker(p_i(\phi))\) heißt der \ul{Eigenraum} von \(\phi\) bzgl. des Eigenfaktors \(p_i(x)\):
(b) Der \(K\)-Untervektorraum \(Gen(\phi, p_i(x))=BigKer(p_i(\phi))\) heißt der \ul{verallgemeinerte  Eigenraum} (oder \ul{Hauptraum}) von \(\phi\) bzgl. \(p_i(x)\).
\subsubsection{Bemerkung}
Ist \(p_i(x)=x-\lambda\) mit \(\lambda\in K\) Eigenwert, so gilt:
(a) \(Eig(\phi,p_i(x))=Ker(\phi-id_V)=Eig(\phi,\lambda)\).
(b) \(Gen(\phi,p_i(x))=BigKer(\phi-\lambda\cdot id_V)=Ker(\phi-\lambda\cdot id_V)^m=\underset{Hau(\phi, \lambda)}{Gen(\phi, \lambda)}\). TODO PFEIL m>>0 BEI m
\subsubsection{Lemma}
Sei \(p(x)\in K[x]\backslash\{0\}\) ein Vielfaches von \(\mu_\phi(x)\). Es gelte \(p(x)=q_1(x)q_2(x)\) mit \(ggT(q_1(x),q_2(x))=1\). Ferner sei \(W_1=Ker(q_1(\phi))\) und \(W_2=Ker(q_2(\phi))\). Dann gilt:
(a) Für jedes \(f\in K[x]\) sind \(W_1\) und \(W_2 f(\phi)\)-invariant.
(b) Für \(i \neq j\) ist \(q_i(\phi)\Big|_{W_j}: W_j \rightarrow W_j\) ein Isomorphismus. TODO Einschränkung
(c) \(V=W_1 \oplus W_2\)
(d) Ist \(p(x)=\mu_\phi(x)\), so gilt \(q_i(x)=\mu_{\phi_{|_{W_i}}}(x)\) für \(i=1,2\). TODO Einschränkung
\ul{Beweis:}
"a" Da \(f(\phi),q_1(\phi),q_2(\phi)\) kommentieren, gilt für \(v\in W_i=Ker(q_i(\phi))\) dass \(q_i(\phi)\underbrace{f(\phi)(v)}_{z.z.\in W_i}=f(\phi)q_i(\phi)(v)=f(\phi)(0)=0\) und somit \(f(\phi)(v)\in Ker(q_i(\phi))=W_i\).\\
"b" Wegen \(ggT(q_1(x),q_2(x))=1\) gibt es \(f_1(x),f_2(x)\in K[x]\) mit \(f_1(x)\cdot q_1(x)+f_2(x)\cdot q_2(x)=1\). Für \(v\in V\) folgt damit \(f_1(\phi)q_1(\phi)(v)+f_2(\phi)q_2(\phi)(v)=v\) (*). TODO EINRAHMEN\\
Hieraus folgt \(W_1 \cap W_2 = Ker(q_1(\phi)) \cap Ker(q_2(\phi))={0}\) nach (*) und daher ist \(q_i(\phi)|W_j:W_j\rightarrow W_j\) injektiv, also bijektiv. TODO Einschränkung
"c" Es ist nur noch zu zeigen, dass \(V=W_1+W_2\) gilt. Sei \(v\in V\). Schreibe \(v=w_1+w_2\) mit \(w_i=f_i(\phi)q_i(\phi)(v)\) nach (*).\\
Dann folgt für \(j \neq i q_j(\phi)(w_i)=q_j(\phi)f_i(\phi)q_i(\phi)(v)=f_i(\phi)\underbrace{p(\phi)}_{=0}(v)=0\) und somit \(w_i\in Ker(q_j(\phi))=W_j\). Dies zeigt \(v\in W_1+W_2\).
"d" Sei \(q_i'(x)\) das Minimalpolynom von \(\phi\Big|_{W_i}\).
Nach Def. von \(W_j\) gilt \(q_i'(x)\Big|_{q_i(x)}\), denn \(q_i(\phi\Big|_{W_i})=q_i(\phi)\Big|_{W_i}=0\).
Also sind auch \(q_1'(x)\) teilerfremd und \(q_1'(x)q_2'(x)=\mu_\phi(x)=q_1(x)q_2(x)\), also \(q_1'(x)=q_1(x)\) und \(q_2'(x)=q_2(x)\). TODO Einschränkung
\qed
\subsubsection{Definition}
Ein Endomorphismus \(\phi\in End_K(V)\) heißt \ul{nilpotent}, wen es ein \(m\geq 1\) gibt mit \(\phi^m=0\). In diesem Fall heißt das kleinste solche m der \ul{Nilpotenzindex} von \(\phi\) und wird mit \(nix(\phi)\).
\subsubsection{Beispiel}
Sei \(\phi\in End_\mathbb{Q}(\mathbb{Q}^3)\) mit \(M_\xi^\xi(\phi)= TODO MATRIX\). Dann gilt \(M_\xi^\xi(\phi^2)=TODO MATRIX\) und \(\phi^3=0\), also \(nix(\phi)=3\).
\subsubsection{Lemma}
Seien \(U', U''\) zwei \(\phi\)-invariante \(K\)-Untervektorräume von \(V\) mit \(V=U' \oplus U''\).
Sei \(\phi'=\mu_{\phi \Big|_{U'}}\) und \(\phi''=\mu_{\phi \Big|_{U''}}\). Dann gilt \(\mu_\phi(x)=kgV(\mu_{\phi \Big|_{U'}}(x),\mu_{\phi \Big|_{U''}}(x))\).\\
\ul{Beweis:}\\
Es gilt \(\mu_\phi(\phi)=0\). Also folgt \(\mu_\phi(\phi\Big|_{U'})=0\) und \(\mu_\phi(\phi \Big|_{U''})=0\). Also ist \(\mu_\phi\) ein gemeinsames Vielfaches von \(\mu_{\phi'}\) und \(\mu_{\phi''}\). Umgekehrt sei \(f(x)=kgV(\mu_{\phi'},\mu_{\phi''}(x))\). Zu zeigen: \(f(\phi)=0\). Betrachte \(f(\phi)\backslash U'=f(\phi \Big|_{U'})=0\) da \(f\) ein Vielfaches von \(\mu_{\phi'}\) ist. Genauso gilt \(f(\phi) \Big|_{U''}=f(\phi|U'')=0\). Wegen \(V=U' \oplus U''\) folgt \(f(\phi)=0\), also \(\mu_\phi \Big|_{f}\).
\qed
\subsubsection{Theorem (Die verallgemeinerte Eigenraumzerlegung / Die Hauptraumzerlegung / Die Primärzerlegung von \(\phi\))}
Sei \(\phi\in End_K(V)\) und \(\mu_\phi(x)=p_1(x)^{m_1}\dots p_s(x)^{m_s}\) die Zerlegung in Eigenfaktoren.
(a) \(V=Gen(\phi,p_1(x)) \oplus \dots \oplus Gen(\phi, p_s(x))\).
(b) Die Einschränkung von \(p_i(\phi)\) auf \(\underbrace{Gen(\phi,p_i(x))}_{G_i}\) ist nilpotent mit \(nix(p_i(\phi)\Big|_{G_i})=m_i\).
(c) Die Einschränkung von \(p_i(\phi)\) auf \(G_j\) mit \(j \neq i\) sind Isomorphismen.
(d) Es gibt \(G_i=Gen(\phi,p_i(x))=Ker(p_i(\phi)^{m_i})=BigKer(p_i(\phi))\)
\ul{Beweis:}\\
Wir schließen mit vollständiger Induktion nach \(s\).\\
\ul{\(s=1\)}: Sei \(\mu_\phi(x)=p_1(x)^{m_1}\). Dies bedeutet \(p_1(\phi)^{m_1}=0\), d.h. \(p_1(\phi)\) ist nilpotent und \(nix(p_1(\phi))=m_1\) nach Def. von \(\mu_\phi(x)\). Offenbar folgt \(V=Ker(p_1(\phi)^{m_1})=BigKer/p_1(\phi))\).\\
\ul{\(s > 1\)}: Verwende das Lemma mit \(q_1(x)=p_1(x)^{m_1}\dots p_{s-1}(x)^{m_{s-1}}\) und \(q_2(x)=p_s(x)^{m_s}\). Nach Teil (c) des Lemmas folgt \(V=Ker(q_1(\phi)) \oplus Ker(q_2(\phi))\underset{I.V.}{=}(Ker(p_1(\phi))^{m_1} \oplus \dots \oplus Ker(p_{s-1}(\phi)^{m_{s-1}}) \oplus Ker(p_s(\phi)^{m_s})\). Nach Teil (d) des Lemmas ist jeweils \(p_i(x)^{m_i}\) das Minimalpolynom von \(p_i|G_i\), Dies beweist (b). Teil (c) folgt aus Teil (b) des Lemmas. Teil (d) folgt aus (b).
TODO UNDERSET
\qed
\subsubsection{Beispiel}
Sei \(K = \mathbb{Q}\) und \(\phi \in End_\mathbb{Q}(\mathbb{Q}^3)\) mit Matrix \(M_\chi^\chi(\phi)=\begin{pmatrix}
e4 & e5 & e6 & e7 & e3 & e7 & e8 & e3
\end{pmatrix}\).\\
Dann \(\mu_\phi(x)=x^6-x^2=x^2(x-1)(x+1)(x^2+1)\)\\
\(\xi_\phi(x)=x^4(x-1)(x+1)(x^2+1)\)\\
Nun berechnen wir: \(Gen(\phi, x+1)=Ker(\phi+id_V)=<(0,0,1,0,0,-1,1,-1)>\)\\
\(Gen(\phi, x-1)=Ker(\phi-id_V)=<(0,0,-1,0,0,-1,-1,-1)>\)\\
\(Gen(\phi, x^2+1)=Ker(\phi^2+id_V)=<(0,0,1,0,0,0,-1,0)<(0,0,0,0,0,1,0,-1)>\)\\
\(Gen(\phi, x)=BigKer(\phi)=Ker(\phi^2)=<(0,0,0,1,0,-1,0,0),(0,0,0,0,1,0,0,-1),(1,0,-1,0,0,0,0,0),(0,1,0,0,0,0,-1,0)>\)\\
Insgesamt folgt \(V=Ker(\phi+id_V)\oplus Ker(\phi-id_V) \oplus Ker(\phi^2+id_V)\oplus Ker(\phi^2)\).\\
Beachte: \(\underbrace{Ker(\phi)}_{=<e_4-e_6,e_5-e_8>} \subsetneq Ker(\phi^2)\).
\subsection{Nilpotente Endomorphismen (Buch: §4.5-4.6}
Sei \(K\) ein Körper, \(V\) ein endlich-dimensionaler \(K\)-Vektorraum und \(\phi\in End_K(V)\).
\(\phi\) nilpotent \(\Leftrightarrow\) es gibt ein \(m\geq 1\) mit \(\phi^m=0\). Das minimale solche \(m\) heißt der Nilpotenzindex \(nix(\phi)\).\\
Im Folgenden sei \(\phi\) nilpotent und \(m=nix(\phi)\).
\subsubsection{Definition}
(a) Die Kette \({0} \subsetneq Ker(\phi) \subsetneq Ker(\phi^2) \subsetneq \dots \subsetneq Ker(\phi^m)=V\) heißt die \ul{kanonische Filtrierung} von \(V\) bzgl. \(\phi\).
(b) Für \(i=1,\dots,m\) sei \(\delta_i=dim_K Ker(\phi^i)-dim_K(Ker(\phi^{i-1})\).
\subsubsection{Lemma}
Für \(i \geq 1\) gilt: \(\phi(Ker(\phi^i))\subseteq Ker(\phi^{i-1})\)\\
\proof
Dies folgt aus \(v\in Ker(\phi^i)\Rightarrow \phi^{i-1}(\phi(v))=0\Rightarrow \phi(v)\in Ker(\phi^{i-1})\).
\qed
\subsubsection{Bemerkung}
Sei \(\phi\) nilpotent mit \(m=nix(\phi)=2\).\\
Dann gilt: \(\{0\}\subsetneq Ker(\phi)\subsetneq Ker(\phi^2) =V\). Wähle ein Komplement \(U_2\) und \(Ker(\phi)\) in \(V\) und erhalte: \(V = Ker(\phi)\oplus U_2\).
Nach dem Lemma gilt: \(\phi(Ker(\phi^1))\subseteq Ker(\phi^0)=\{0\}\) und \(\phi(U_2)=\phi(V)=\phi(Ker(\phi^2))\subseteq Ker(\phi)\).\\
Wähle nun ein Komplement \(U_1\) von \(\phi(U_2)\) in \(Ker(\phi)\) und erhalte: \(v=Ker(\phi)\oplus U_2=U_1\oplus U_2\oplus \phi(U_2)\).\\
Wegen \(U_2\cap Ker(\phi)=\{0\}\) gilt dabei \(\phi EINGESCHR_{U_2}\) ist injektiv und somit \(dim_K(\phi(U-_2))=dim_K(U_2)\).\\
Also folgt: \(\delta_1=dim_K(Ker(\phi))=dim_K(U_1)+dim_K(\phi(U_2))\)\\
\(\delta_2=dim_K(V)-dim_K(Ker(\phi))=dim_K(U_2)\).
\subsubsection{Satz (Die Jordan-Zerlegung nilpotenter Endomorphismen)}
Sei \(\phi\in End_K(V)\) nilpotent und \(s=nix(\phi)\). Für\( i=1,\dots,s\) sei \(\delta_i=dim_K(Ker(\phi^i))-dim_K(Ker(\phi^{i-1}))\).\\
Konstruiere Untervektorräume \(U_1,\dots U_s\) von \(V\) rekursiv wie folgt:\\
(1) Sei \(U_s\) ein Komplement von \(Ker(\phi^{s-1})\) in \(V\).
(2) Absteigend für \(i=s-1, s-2,\dots, 1\) sei \(U_i\) ein Komplement von \(Ker(\phi^{i-1})+\phi^{s-i}(U_s)+\phi^{s-i-1}(U_{s-1})+\dots+\phi^1(U_{i+1})\) in \(Ker(\phi^i)\).\\
Dann gilt: (a) \(V=U_1\)\\
\(\oplus U_2\oplus \phi(U_2)\)\\
\(\oplus U_3\oplus \phi(U_3)\oplus \phi^2(U_3)\)\\
\vdots\\
\(\oplus U_s\oplus \phi(U_s)\oplus\dots\oplus\phi^{s-1}(U_s)\)\\
Diese Darstellung heißt die \ul{Jordan-Zerlegung} von \(V\) bzgl. \(\phi\).
(b) Für \(i=1,\dots,s\) gilt: \(\delta_i=\sum_{j=i}^{s} dim_K(U_j)\) und \(\delta_1\geq\delta_2\geq\dots\geq\delta_s>0\).\\
\ul{Beweis:} Vgl. Buch S.265-267.
\subsubsection{Korollar}
(a) Gilt \(\delta_1=\dots=\delta_s=1\), so folgt \(U_1=\dots=U_{s-1}=\{0\}\) und \(V=U_s\oplus \phi(U_s)\oplus\phi^2(U_s)\oplus\dots\oplus\phi^{s-1}(U_s)\).\\
Dabei gilt: \(Ker(\phi^i)=\phi^{s-i}(U_s)\oplus\dots\oplus\phi^{s-1}(U_s)\).
(b) Gilt \(\delta_1=1\), so folgt \(\delta_2=\dots=\delta_s=1\). In diesem Fall liefert jeder Vektor \(v\in V\backslash Ker(\phi^{s-1})\) ein Basistupel \(B=(v,\phi(v),\phi^2(v),\dots,\phi^{s-1}(v))\).\\
In dieser Basis gilt \(M_B^B(\phi)=\begin{pmatrix}
0 & 0 & & & 0\\
1 & 0 & \mbox{\Huge 0} & & \vdots\\
0 & 1 & & & \vdots\\
\vdots & \vdots & \ddots & & 0\\
0 & 0 & \hdots & 1 & 0
\end{pmatrix}\). TODO MATRIX SCHAUEN OB RICHTIG
Eine solche Matrix heißt ein \ul{Jordan-Kästchen}.\\
In der Basis \(B'=(\phi^{s-1}(v),\phi^{s-2}(v),\dots,v)\) gilt \(M_{B'}^{B'}(\phi)\)=TODO MATRIX (Dies ist das üblichere Jordan-Kästchen).\\
\proof
"(a)" Nach Teil (b) des Satzes folgt \(U_1=\dots=U_{s-1}=\{0\}\). Damit vereinfacht sich die Jordan-Zerlegung wie angegeben.
"(b)" folgt aus Teil (b) des Satzes und (a).
\qed
\subsubsection{Bemerkung}
Sei \(\delta_s\geq 1\) und \(\{v_1,\dots,v_\delta\}\) eine Basis von \(U_s\). Dann ist \(B=\{v_1,\phi(v_1),\dotsm\phi^{s-1}(v_1)\}\cup\dots\cup\{v_\delta,\phi(v_\delta),\dotsm\phi^{s-1}(v_\delta)\}\) eine Basis von \(W=U_s\oplus\phi(U_s)\oplus\dots\oplus\phi^{s-1}(U_s)\). Die Matrix von \(\phi|W\) bzgl. \(B\) ist blockdiagonal mit \(\delta_s\) Jordan-Kästchen auf der Hauptdiagonalen \(M_B^B(\phi|W)\)=TODO MATRIX  TODO CAPREV u.\\
\subsubsection{Satz (Die Jordansche Normalform)}
Sei \(\phi\in End_K(V)\) mit linearen Eigenfaktoren, also mit \(\chi_\phi(x)=(x-\lambda_1)^{a_1}\cdot\dots\cdot(x-\lambda_s)^{a_s}\). Dann gibt es eine Basis \(B\) in \(V\), so dass gilt: \(M_B^B(\phi)=\begin{pmatrix}
\lambda_1 I_{a_1}N_1 & & 0 \\
 & \ddots & \\
0 & & \lambda_s I_{a_s}N_s
\end{pmatrix}\) mit \(\lambda_i\cdot I_{a_i}+N_i=\begin{pmatrix}
\mbox{\fbox{\(\begin{matrix}
		\lambda_i & 1 & & 0\\
		& \ddots & \ddots & \\
		& & \ddots & 1 \\
		0& & & \lambda_i
		\end{matrix}\)}} & & \mbox{\Huge0} \\
	 & \ddots & \\
	 \mbox{\Huge0} & & \mbox{\fbox{\(\begin{matrix}
	 		\lambda_i & 1 & & 0\\
	 		& \ddots & \ddots & \\
	 		& & \ddots & 1 \\
	 		0& & & \lambda_i
	 		\end{matrix}\)}}
\end{pmatrix}\), wobei die Größe der \ul{Jordan-Blöcke} \fbox{\(\begin{matrix}
\lambda_i & 1 & & 0\\
& \ddots & \ddots & \\
& & \ddots & 1 \\
0& & & \lambda_i
\end{matrix}\)} durch die Jordan-Zerlegung von \((\phi-\lambda_iid_V)\Big|_{G_i}\) mit \(G_i=Gen(\phi,\lambda_i)\) gegeben ist.
\subsection{Diagonalisierbarkeit und Triagonalisierbarkeit (Buch: §4.3-4.4)}
Sei \(K\) ein Körper, \(V\) ein endlich-dimensionaler \(K\)-Vektorraum, \(\phi\in End_K(V)\).\\
\(\phi\) heißt diagonalisierbar \(\Leftrightarrow\) es gibt eine Basis von V bestehend aus Eigenvektoren von \(\phi \Leftrightarrow\) es gibt eine Basis \(B\) von \(V\), so dass \(M_B^B(\phi)\) eine Diagonalmatrix ist.
\subsubsection{Satz (Zweite Charakterisierung diagonalisierbarer Endomorphismen)}
Die folgenden Bedingungen sind äquivalent:
(a) \(\phi\) ist diagonalisierbar
(b) Alle Eigenfaktoren von \(\phi\) sind linear und \(Eig(\phi,\lambda)=Gen(\phi,\lambda)\) für alle Eigenwerte \(\lambda\) von \(\phi\)
(c) \(\mu_\phi(x)\) zerfällt in ein Produkt paarweise verschiedener Faktoren \(x-\lambda_i\).\\
\proof
"(a)\(\Rightarrow\)(b)" Sei \(B\) eine Basis von \(V\), so dass \(M_B^B(\phi)\) eine Diagonalmatrix ist. Dann ist \(\chi_\phi(x)=(x-\lambda_1)^{a_1}\cdot\dots\cdot(x-\lambda_s)^{a_s}\) mit \(\lambda_i\neq\lambda_j\) und \(a_i\geq 1\) und \(M_B^B(\phi)\)=TODO MATRIX und \(B=B_1\cupdot\dots\cupdot B_s\) und \(Eig(\phi,\lambda_i)=<B_i>_K=Gen(\phi,\lambda_i)\)
"(b)\(\Rightarrow\)(c)" \ul{z.z.} \(m_i=1\) für \(1,\dots,s\) (vgl. Übungsblatt 3, Aufgabe 7).
"(c)\(\Rightarrow\)(a)" Schreibe \(\mu_\phi(x)=(x-\lambda_1)\cdot\dots\cdot(x-\lambda_s)\) mit \(\lambda_i\neq\lambda_j\) für \(i\neq j\).\\
Nach Übungsblatt 3, Aufgabe 7 gilt \(Eig(\phi,\lambda_i)=Gen(\phi,\lambda_i)\) für \(i=1,\dots,s\).\\
Dann folgt \(V=Gen(\phi,\lambda_1)\oplus\dots\oplus Gen(\phi,\lambda_s)=Eig(\phi,\lambda_1)\oplus\dots\oplus Eig(\phi,\lambda_s)\). Somit hat \(V\) eine Basis bestehend aus Eigenvektoren von \(\phi\).
\qed
\subsubsection{Definition}
Der Endomorphismus \(\phi\) heißt \ul{triagonalisierbar}, wenn es eine Basis von \(V\) gibt, so dass \(M_B^B(\phi)\) eine obere Dreiecksmatrix ist.
\subsubsection{Satz (Charakterisierung triagonalisierbarer Endomorphismen)}
Genau dann ist \(\phi\) triagonalisierbar, wenn alle Eigenfaktoren von \(\phi\) linear sind.\\
\proof
"\(\Rightarrow\)" Sei \(B\) eine Basis von \(V\) bzgl. der \(M_B^B(\phi)\) eine obere Dreiecksmatrix ist. Schreibe \(M_B^B(\phi)=\)TODO MATRIX und erhalte \(\chi_\phi(x)=det(M_B^B(\phi))-x\cdot I_n)=(-1)^n(x-\lambda_1)\cdot\dots\cdot (x-\lambda_n)\).
"\(\Leftarrow\)" Dies folgt aus der Jordan-Zerlegung.
\qed
\section{Bilineare Abbildungen}
\setcounter{subsection}{24}
\subsection{Grundlegendes zu Bilinearformen (Buch §5.1,5.4)}
Sei \(K\) ein Körper und \(V\) ein endlich-dimensionaler \(K\)-Vektorraum mit \(n=dim_K(V)\).
\subsubsection{Definition}
(a) Sei \(W\) ein weiterer K-Vektorraum. Eine Abbildung \(\Phi:V\times V\rightarrow W\) heißt \ul{\(K\)-bilinear}, wenn für alle \(v,v_1,v_2,\tilde{v}, \tilde{v_1}, \tilde{v_2} \in V\) und \(a_1, a_2\in K\) gilt:
(a) \(\Phi(a_1v_1+a_2v_2,\tilde{v})=a_1\cdot\Phi(v_1,\tilde{v})+a_2\cdot\Phi(v_2,\tilde{v})\)
(b) \(\Phi(v,a_1\tilde{v_1}+a_2\tilde{v_2})=a_1\cdot\Phi(v,\tilde{v_1})+a_2\cdot\Phi(v,\tilde{v_2})\).
(b) Eine bilineare Abbildung \(\Phi:V\times V\rightarrow K\) heißt auch eine \ul{Bilinearform} auf V.
\subsubsection{Bemerkung (Längenmessung in \(\mathbb{R}^2\))}
Sei \(v=(a_1,a_2)\in\mathbb{R}^2\) mit \(a_1,a_2\in\mathbb{R}\). Dann heißt \(l(v)=||v|| = \sqrt{a_1^2+a_2^2}\) die \ul{Länge} (oder die \ul{Norm}) von \(v\).
\subsubsection{Definition}
Sei \(v=(a_1,a_2)\in\mathbb{R}^2\backslash\{0\}\). Dann heißt \(e_v=\frac{v}{||v||}=(\frac{a_1}{\sqrt{a_1^2+a_2^2}},\frac{a_2}{\sqrt{a_1^2+a_2^2}})\) der \ul{Einheitsvektor} in \ul{Richtung} \(v\).
\subsubsection{Bemerkung (Winkelmessung in \(\mathbb{R}^2\))}
Seien \(v=(a_1,a_2)\) und \(w=(b_1,b_2)\) zwei Vektoren in \(\mathbb{R}^2\backslash\{0\}\).\\
Gesucht ist eine Funktion \(\Phi:\mathbb{R}^2\times\mathbb{R}^2\rightarrow\mathbb{R}\), mit deren Hilfe wir den Winkel \(\alpha=\sphericalangle(v,w)\) zwischen \(v\) und \(w\) definieren können.
(a) Der Winkel \(\alpha\) sollte nicht von \(||v||\) und \(||w||\) abhängen. Es gilt: \(cos(\alpha)=\frac{||u||}{||w||}\), wobei \(u\) der Fußpunkt des Lots von \(w\) auf \(v\) ist.
(b) Gilt \(w\bot v\) (d.h. steht \(w\) senkrecht auf \(v\)), so gilt \(cos(\alpha)=0\) und \(u=0\).
(c) Genauer gilt: \(u=||u||\cdot e_v =||w||\cdot cos(\alpha)\cdot e_v\)
(d) Nach der Vektoraddition gilt \(w=u+\tilde{u}\)\\
Ferner gilt \(\tilde{u}\bot v\).
(1) Gilt \(\Phi(v,u+\tilde{u})=\Phi(v,u)+\underbrace{\Phi(v,\tilde{u})}_{=0 \text{ da } \tilde{u}\bot v}\), so folgt \(\Phi(v,w)=\Phi(v,u)\) und somit \(\Phi(v,w)=\Phi(\norm{v}\cdot e_v, ||w||\cdot cos(\alpha)\cdot e_v)\)
(e) Gilt (2) \(\Phi(\lambda \tilde{v}, \tilde{w})=\Phi(\tilde{v},\lambda \tilde{w})=\lambda\Phi(\tilde{v},\tilde{w})\), so folgt \(\Phi(v,w)=||v||\cdot||w||\cdot cos(\alpha)\cdot\underbrace{\Phi(e_v,e_v)}_{\text{Winkel }0\degree,\text{ }cos(\alpha)=1}\).
(f) Gilt (3) \(\phi(v,v)=||v||^2\), so folgt \(\Phi(e_v,e_v)=\Phi(\frac{v}{||v||},\frac{v}{||v||})\frac{1}{||v|||^2}\cdot||v||^2=1\) und damit \(\Phi(v,w)=||v||\cdot ||w||\cdot cos(\alpha)\), also \(cos(\alpha)= \frac{\Phi(v,w)}{||v||\cdot||w||}\).
Insgesamt sollte \(\Phi\) folgende Eigenschaften erfüllen:
(1) \(\Phi(v,w_1+w_2)=\Phi(v,w_1)+\Phi(v,w_2)\) für \(v,w_1,w_2\in\mathbb{R}^2
\Phi(v_1,+v_2w)=\Phi(v_1,w)+\Phi(v_2,w)\) für \(v_1,v_2,w\in\mathbb{R}^2\)
(2) \(\Phi(\lambda v,w)=\Phi(v,\lambda w)=\lambda\Phi(v,w)\) für \(\lambda\in\mathbb{R}\) und \(v,w\in\mathbb{R}^2\)
(3) \(\Phi(v,w)=0\) falls \(v \bot w\)
(4) \(\Phi(v,v)=||v||^2\) für \(v\in\mathbb{R}^2\)
Kann man hieraus \(\Phi\) bestimmen? Für \(v=(a_1,a_2)\) und \(w=(b_1,b_2)\) folgt:
\(\Phi(v+w,v+w)=||v+w||^2=||(a_1+b_1,a_2+b_2)||^2=(a_1+b_1)^2+(a_2+b_2)^2=a_1^2+a_2^2+b_1^2+b_2^2+2(a_1b_1+a_2b_2)\)\\
\(\Phi(v+w,v+w)=\Phi(v,v)+\Phi(v,w)+\underbrace{\Phi(w,v)}_{=\Phi(v,w)}+\Phi(w,w)=||v||^2+||w||^2+2\Phi(v,w)=a_1^2+a_2^2+b_1^2+b_2^2+2\Phi(v,w) \Rightarrow \Phi(v,w)=a_1b_1+a_2b_2\).
Wie man leicht nachprüft, erfüllt dieses \(\Phi\) die Eigenschaften (1)-(4).
Der Winkel \(\alpha=\sphericalangle(v,w)\) ist dann durch \(cos(\alpha)=\frac{\Phi(v,w)}{||v||\cdot||w||}\) definiert.
\subsubsection{Definition}
Sei \(B=(v_1,v_2,\dots,v_n)\) ein Basistupel von \(V\).
Dann ist die Abbildung \(\Phi :\underset{(a_1v_1+\dots+a_nv_n,b_1v_1+\dots+b_nv_n)\mapsto a_1b_1+a_2b_2+\dots+a_nb_n}{V\times V\rightarrow K}\) eine Bilinearform auf \(V\). Sie heißt die \ul{Standardbilinearform} auf \(V\) bzgl. der Basis \(B\).
\subsubsection{Definition}
Sei \(B=(v_1,\dots,v_n)\) ein Basistupel von \(V\).
(a) Ist \(\Phi:V\times V\rightarrow K\) eine Bilinearform auf \(V\), so heißt die Matrix \(G_B^B(\Phi)=(\phi(v_i,v_j))_{i,j}\in Mat_n(K)\) die \ul{Gramsche Matrix} (oder die \ul{Strukturmatrix}) von \(\Phi\).
(b) Die Menge aller Bilinearformen auf \(V\) wird mit \(Bil_K(V)\) bezeichnet.
\subsubsection{Satz}
Sei \(B=(v_1,\dots,v_n)\) ein Basistupel von \(V\).
(a) Zu jeder Matrix \(A=(a_{ij})\in Mat_n(K)\) definiere \(\Phi_A:V\times V\rightarrow K\) durch \(\Phi_A(b_1v_1+\dots+b_nv_n,c_1v_1+\dots+c_nv_n)=\sum_{i=1}^{n}\sum_{j=1}^{n}b_ic_ja_{ij}\). Dann ist \(\Phi_A\) eine Bilinearform auf \(V\) und \(G_B(\Phi_A)=A\).
(b) Die beiden Zuordnungen \(\Phi_A\rightarrow G_B(\Phi)\) und \(A\rightarrow \Phi_A\) sind invers zueinander.
(c) Die Menge \(Bil_K(V)\) ist bzgl. \((\Phi+\Psi)(v,w)=\Phi(v,w)+\Psi(v,w)\) und \((\lambda\Phi)(v,w)=\lambda\cdot\Phi(v,w)\) für \(v,w\in V\) und \(\lambda\in K\) ein \(K\)-Vektorraum.
(d) Die Abbildung \(\phi:\underset{\Phi\mapsto G_B(\Phi)}{Bil_K(V)\rightarrow Mat_n(K)}\) ist ein Isomorphismus von \(K\)-Vektorräumen.
(e) Die Standardbilinearform \(\Phi\) erfüllt \(G_B(\phi)=I_n\).\\
\proof
"(a)" \ul{z.z.} \(\Phi_A\) ist \(K\)-bilinear. Beachte: \(\Phi(b_1v_1+\dots+b_nv_n, c_1v_1+\dots+c_nv_n)=(b_1,\dots,b_n)\cdot A\cdot \begin{pmatrix}
c_1\\
\vdots\\
c_n
\end{pmatrix}\).
Gilt \(v=v'+v''\) mit \(v'=b_1'v_1+\dots+b_n'v_n\) und \(v''=b_1''v_1+\dots+b_n''v_n\) und \(w=c_1v_1+\dots+c_nv_n\) so folgt:
\(\Phi(v'+v'',w)=(b_1'+b_1'',\dots,b_n'+b_n'')\cdot A \cdot \begin{pmatrix}
c_1\\
\vdots\\
c_n
\end{pmatrix}=(b_1',\dots,b_n')\cdot A \cdot \begin{pmatrix}
c_1\\
\vdots\\
c_n
\end{pmatrix}+(b_1'',\dots,+b_n'')\cdot A \cdot \begin{pmatrix}
c_1\\
\vdots\\
c_n
\end{pmatrix}=\Phi(v',w)+\Phi(v'',w)\).\\
Analog rechnet man die anderen Bedingungen nach.\\
Die Gramsche Matrix \(G_B(\Phi_A)\) hat als \((a_{ij})\)-Eintrag gerade \(\Phi(v_i,v_j)=e_i^{tr}\cdot A \cdot e_j=e_i^{tr}\cdot \underbrace{A\cdot e_j}_{j\text{-te Spalte von} A}=a_{ij}\) also der \((i,j)\)-Eintrag von \(A\).\\
Es folgt \(G_B(\Phi_A)=A\).
"(b)" Soeben gezeigt ist \(G_B(\Phi_A)=0\). Die Behauptung \(\Phi_{G_B(\Phi)}=\Phi\) folgt, wenn wir zeigen, dass für alle \(i,j=1,\dots,n\) gilt:\(\Phi_{G_B(\Phi)}(v_i,v_j)=\Phi(v_i,v_j)\). Wie gesehen ist \(\phi_{G_B(\Phi)}(v_i,v_j)\) gerade der \((i,j)\)-Eintrag der Matrix \(G_B(\Phi)\). Dieser ist nach Definition von \(G_B(\Phi)\) gleich \(\Phi(v_i,v_j)\).
"(c)" \ul{z.z.} \(\Phi+\Psi,\lambda\cdot\Phi\) sind Bilinearformen: Nachrechnen!\\
\ul{z.z.} \(Bil_K(V)\) erfüllt bzgl. \(+,\cdot\) die Vektorraumaxiome: Nachrechnen!
"(d)" Die Bijektivität von \(\phi\) folgt aus (b).\\
\ul{z.z.} \(\phi\) ist \(K\)-linear: Seien \(\Phi,\Psi\in Bil_K(V)\) und \(\lambda,\mu\in K\). Dann gilt \(\phi(\lambda\Phi+\mu\Psi)=((\lambda\Phi+\mu\Psi)(v_i,v_j))_{i,j}=(\lambda\Phi(v_i,v_j)+\mu\Psi(v_i,v_j))_{i,j}=\lambda\cdot(\Phi(v_i,v_j))_{i,j}+\mu\cdot(\Psi(v_i,v_j))_{i,j}=\lambda\phi(\Phi)+\mu\phi(\Psi)\).
"(e)" Für \(\Phi(a_1v_1+\dots+a_nv_n,b_1v_1+\dots+b_nv_n)=a_1b_1+\dots+a_nb_n\) gilt \(\Phi(v_i,v_j)=e_i^{tr}e_j=\rho_{ij}=\begin{cases}
1,& \text{falls }i=j\\
0,& \text{sonst}
\end{cases}\), also \(G_B(\Phi)=(\rho_{ij})=I_n\).
\qed
\ul{Frage:} Was passiert bei einem Basiswechsel mit der Gramschen Matrix?
\subsubsection{Satz}
Seien \(B=(v_1 \dots v_n)\) und \(V=(w_1 \dots w_m)\) zwei Basen von \(V\) und sei \(T_C^B=(t_{ij})\in Mat_n(K)\) die Transformationsmatrix (d.h. die j-te Spalte von \(T_C^B\) enthält die Koordinaten von \(v_j\) in der Basis \(C\)). Ferner sei \(\Phi:V\times V\rightarrow K\) eine Bilinearform.\\
Dann gilt: \(G_B(\Phi)=(T_C^B)^{tr}\cdot G_C(\Phi)\cdot T_C^B\).\\
\proof
Für \(v,w\in V\) schreibe \(v=a_1v_1+\dots+a_nv_n=a_1'w_1+\dots+a_n'w_n und w=b_1v_1+\dots+b_nv_n=b_1'w_1+\dots+b_n'w_n \) mit \(a_i,a_j',b_k,b_l'\in K\). Dann
\(TODO MATRIX
=T_C^B\cdot TODO MATRIX\) und \(TODO MATRIX = T_C^B\cdot TODO MATRIX\). Dann gilt: \(\Phi(v,w)=(a_1,\dots,a_n)G_B(\Phi) TODO MATRIX = (a_1',\dots,a_n')\cdot G_C(\Phi) TODO MATRIX=(a_1',\dots,a_n')=(a_1,\dots,a_n)\cdot (T_C^B)^{tr} =(a_1,\dots,a_n)(T_C^B)^{tr}\cdot G_C(\Phi)\cdot T_C^B TODO MATRIX\). Setzt man \((a_1,\dots,a_n)=e_i\) und \((b_1,\dots,b_n)=e_j\), so ist \(e_i^{tr}\underbrace{Me_j}_{j\text{-te Spalte von } M}=(i,j)-\)Eintrag von \(M\). Für alle \(i,j=1,\dots,n\) ist also der \((i,j)\)-Eintrag von \(G_B(\Phi)\) gleich dem \((i,j)\)-Eintrag von \((T_C^B)^{tr}\cdot G_C(\Phi)T_C^B\)
\qed
\subsubsection{Bemerkung}
Ist \(\phi\in End_K(V) \), so gilt \(M_B(\phi)=(T_C^B)^{-1}\cdot M_C(\phi)\cdot T_C^B\) und \(G_B(\phi)=(T_C^B)^{tr}\cdot G_C(\phi)\cdot T_C^B\).
\subsubsection{Definition}
(a) Eine Bilinearform \(\Phi:V\times V\rightarrow K\) heißt \ul{symmetrisch}, wenn für alle \(v,w\in V\) gilt: \(\Phi(v,w)=\Phi(w,v)\)
(b) Eine Bilinearform \(\Phi:V\times V\rightarrow K\) heißt \ul{antisymmetrisch}, wenn für alle \(v,w\in V\) gilt: \(\Phi(v,w)=-\Phi(w,v)\)
\subsubsection{Satz}
Eine Bilinearform \(\Phi:V\times V\rightarrow K\) ist genau dann symmetrisch, wenn \(G_B(\Phi)\) eine symmetrische Matrix ist, d.h. wenn \(G_B(\Phi)=G_B(\Phi)^{tr}\) gilt.\\
\proof
"\(\Rightarrow\)" Für \(i,j=1\dots n\) gilt \(\underbrace{\Phi(v_i,v_j)}_{(i,j)\text{-Eintrag von } G_B(\Phi)}=\underbrace{\Phi(v_j,v_i)}_{(i,j)\text{-Eintrag von } G_B(\Phi)^{tr}}\).
"\(\Leftarrow\)" Sei \(v=a_1v_1+\dots+a_nv_n\) und \(w=b_1v_1+\dots+b_nv_n\) mit \(a_i,b_j\in K\). Dann gilt \(\Phi(v,w)=\sum_{i=1}^{n}\sum_{j=i}^{n}a_ib_j\cdot\Phi(v_i,v_j)=\sum_{i=1}^{n}\sum_{j=i}^{n}a_ib_j\Phi(v_j,vi)=\Phi(w,v)\)
\qed
\ul{Beispiel:} Die Standardbilinearform \(\Phi\) ist symmetrisch, denn \(G_\chi(\Phi)=I_n\) ist symmetrisch.
\subsubsection{Definition}
Sei \(\Phi:V\times V\rightarrow K\) eine Bilinearform.
(a) Zwei Vektoren \(v,w\in V\) heißen \ul{orthogonal} bzgl. \(\Phi\), wenn gilt: \(\Phi(v,w)=0\). \ul{Schreibweise:} \(v\bot_\Phi w\)
(b) Ist \(v\in V\) und \(U\subseteq V\), so heißt \(v\) \ul{orthogonal} zu \(U\), wenn für alle \(u\in U\) gilt \(v\bot_\Phi u\).
(c) Für \(U,W\subseteq V\) sagen wir, dass \(U\) bzgl.\(\Phi\) \ul{orthogonal} ist zu \(W\), falls für alle \(u\in U, w\in W\) gilt: \(u\bot_\Phi w\). \ul{Schreibweise:} \(U\bot_\Phi W\).
\subsubsection{Beispiel}
Ein Vektor \(v\neq 0\) kann zu sich selbst orthogonal sein und zwar sogar bzgl. der Standardbilinearform.\\
Betrachte z.B. \(K=\mathbb{F}_p\) mit \(p\) prim und \(\Phi:\mathbb{F}_p^p\times \mathbb{F}_p^p\rightarrow \mathbb{F}_p\) Standardbilinearform. Dann gilt \(\Phi(\underbrace{(1,1,\dots,1)}_{p},\underbrace{(1,1,\dots,1)}_{p})=1\cdot 1+\dots+1\cdot 1=0\).
\subsubsection{Beispiel}
Ein Vektor \(v\neq 0\) kann zu ganz \(V\) orthogonal sein!\\
Betrachte z.B. \(\Phi:K^2\times K^2\rightarrow K\) mit \(G_\chi(\Phi)=\begin{pmatrix}
1 & -1\\
-1 & 1
\end{pmatrix}\).
Für \(v=(1,1)\) und \(w=(1_1,a_2)\) gilt dann \(\Phi(v,w)=(1,1)\cdot\begin{pmatrix}
1 & -1\\
-1 & 1
\end{pmatrix}\begin{pmatrix}
a_1\\
a_2
\end{pmatrix}=(0,0)\cdot\begin{pmatrix}
a_1\\
a_2
\end{pmatrix}=0\). Also folgt \(v\bot_\Phi K^2\).
\subsubsection{Beispiel}
Sei \(\Phi:\mathbb{R}^2\times\mathbb{R}^2\rightarrow\mathbb{R}\) die Standardbilinearform. Für \(v=(a_1,a_2)\) und \(w=(b_1,b_2)\) gilt \(v\bot_\Phi w\) genau dann, wenn \(a_1b_1+a_2b_2=0\) erfüllt ist. TODO SKIZZE
O.E. sei \(a_2\neq 0\). Dann folgt \(b_2=-\frac{a_1}{a_2}b_1\). Dies liefert \((b_1,b_2)=(b_1,-\frac{a_1}{a_2}b_1)=\underbrace{a_2^{-1}b_1}_{\neq 0}\cdot(a_2,-a_1)\).
\subsubsection{Definition}
Eine Bilinearform \(\Phi:V\times V\rightarrow K\) heißt \ul{nicht ausgeartet}, wenn für \(v\in V\) aus \(v\bot_\Phi V\) folgt, dass \(v=0\) gilt.
\subsubsection{Satz}
Sei \(B=(v_1\dots v_n)\) ein Basistupel von \(V\). genau dann ist \(\Phi\) nicht ausgeartet, wenn \(det(G_B(\Phi))\neq 0\) gilt.\\
\proof
Sei \(v\in V\). Schreibe \(v=a_1v_1+\dots+a_nv_n\) mit \(a_i\in K\). Dann gilt: \(v\bot_\Phi V\Leftrightarrow \Phi(v,v_1)=\Phi(v,v_2)=\dots=\Phi(v,v_n)=0\Leftrightarrow \begin{cases}
a_1\Phi(v_1,v_1)+\dots+a_n\Phi(v_n,v_1)=0\\
\vdots\\
a_1\Phi(v_1,v_n)+\dots+a_n\Phi(v_n,v_n)=0
\end{cases}\)\\
Also folgt: \(\Phi\) nicht ausgeartet \(\Leftrightarrow\) aus \(v\bot_\Phi V\) folgt \(v=0\) \(\Leftrightarrow\) das einzige Tupel \((a_1,\dots,a_n)\), das \((*)\) erfüllt ist \((a_1,\dots,a_n)=(0,\dots,0)\)\\
\(\Leftrightarrow\) \(det(G_B(\Phi))^{tr}\neq 0\) \(\Leftrightarrow\) \(det(G_B(\Phi))\neq 0\).
\qed
\subsubsection{Beispiel}
(a) Die Standardbilinearform \(\Phi:K^n\times K^n\rightarrow K\) ist nicht ausgeartet, denn \(det(G_\chi(\Phi))=det(I_n)=1\neq 0\).
(b) Die Matrix \(\begin{pmatrix}
	1 & -1\\
	-1 & 1
\end{pmatrix}\) definiert eine ausgeartete Bilinearform auf \(K^2\), da \(det\begin{pmatrix}
1 & -1\\
-1 & 1
\end{pmatrix}\neq 0\).
\subsubsection{Definition}
Sei \(\Phi:V\times V\rightarrow K\) eine Bilinearform und \(U\subseteq V\) ein \(K\)-Untervektorraum.
(a) Ein Untervektorraum \(W\subseteq V\) mit \(U\bot_\Phi W\) und \(U\oplus W=V\) heißt ein \ul{orthogonales Komplement} von \(U\).
(b) Die Menge \(U^\bot=\{v\in V|v\bot_\Phi U\}\) heißt der zu \(U\) \ul{orthogonale Raum}.
\subsubsection{Satz (Eigenschaften des orthogonalen Untervektorraums)}
Sei \(\Phi:V\times V\rightarrow K\) eine Bilinearform und seien \(U,W\) \(K\)-Untervektorräume von \(V\).
(a) \(U^\bot\) ist ein \(K\)-Untervektorraum von \(V\).
(b) Ist \(U=<v>\) mit \(v\in V\backslash\{0\}\), so gilt \(U^\bot=<v>^\bot=<av>^\bot\) für alle \(a\in K\backslash\{0\}\),
(c) Gilt \(U\subseteq W\), so folgt \(W^\bot\subseteq U^\bot\).
(d) Ist \(S\subseteq V\) eine Teilmenge, so gilt \(S^\bot=\{v\in V|v\bot_\Phi S\}=<S>_K^\bot\).
(e) Ist \(\Phi\) symmetrisch, so gilt \((U^\bot)^\bot\supseteq U\) und \(((U^\bot)^\bot)^\bot=U^\bot\).\\
\proof
"(a)" Seien \(v_1,v_2\in U^\bot\) und \(a_1,a_2\in K\). Für alle \(u\in U\) gilt dann \(\Phi(a_1v_1+a_2v_2,u)=a_1\Phi(v_1,u)+a_2\Phi(v_2,u)=0\) und somit \(a_1v_1+a_2v_2\in U^\bot\).
"(b)" "\(\subseteq\)" Ist \(w\in<v>^\bot\), also \(\Phi(w,cv)=0\) für alle \(c\in K\), so folgt \(\Phi(w,b\cdot (av))=0\) für alle \(b\in K\), aso \(w\in<av>^\bot\).
"\(\supseteq\)" ist \(w\in<av>^\bot\), also \(\Phi(w,cav)=0\) für alle \(c\in K\), so folgt (mit \(c=a^{-1}\)), dass \(\Phi(w,v)=0\) gilt. Dies liefert \(\Phi(w,bv)=0\) für alle \(b\in K\backslash\{0\}\), also \(w\in<v>^\bot\).
"(c)" Für \(v\in W^\bot\) und \(u\subseteq W\) gilt \(\Phi(v,u)=0\) und somit \(v\in U^\bot\).
"(d)" "\(\supseteq\)" klar "\(\subseteq\)" Sei \(v\in S^\bot\) und \(w\in<S>\). Schreibe \(w=a_1s_1+\dots+a_rs_r\) mit \(a_i\in K\) und \(s_i\in S\) und erhalte \(\Phi(v,w)=a_1\underbrace{\Phi(v,s_1)}_{=0}+\dots+a_r\underbrace{\Phi(v,s_r)}_{=0}=0\). Dies liefert \(v\in<S>^\bot\).
"(e)" Für \(u\in U\) gilt: \(\Phi(v,u)=0\) für alle \(v\in U^\bot\), also \(\Phi(u,v)=0\) für alle \(v\in U^\bot\). Dies zeigt \(u\in(U^\bot)^\bot\), also \(U\subseteq(U^\bot)^\bot\). Nach (e) gilt \(U^\bot\subseteq ((U^\bot)^\bot)^\bot\). Mit (c) folgt aus \(U\subseteq ((U^\bot)^\bot)^\bot\subseteq U^\bot\) gilt.
\qed
\subsubsection{Satz (Dimensionsformel für orthogonale Untervektorräume)}
Sei \(\Phi:V\times V\rightarrow V\) eine nicht ausgeartete Bilinearform und \(U\subseteq V\) ein \(K\)-Untervektorraum.\\
Dann gilt: \(dim_K(U)+dim_K(U^\bot)=dim_K(V)\).\\
(\(\lightning\) Im Allgemeinen gilt \ul{nicht} \(U\cap U^\bot=\{0\}\))\\
\proof
Sei \((u_1,\dots, u_m)\) ein Basistupel für \(U\) und \(C=(w_1,\dots,w_k)\) ein Tupel von Vektoren, so dass \(B\cup C\) ein Basistupel von \(V\) ist. Sei \(v_1,\dots,v_n)\) dieses Basistupel, d.h \(v_i=u_i\) für \(i=1,\dots,m\) und \(v_{m+j}=w_j\) fpr \(j=1,\dots,k\) (mit \(m+k=n\)).\\
\ul{z.z.:} \(dim_K(U^\bot)=k\).\\
Fpr \(v=a_1v_1+\dots+a_nv_n=(a_1v_1+\dots+a_mv_m)+(a_{m+1}v_{m+1}+\dots+a_{m+k}v_{m+k})\) gilt: \(v\in U^\bot\) \(\Leftrightarrow\) \(\begin{cases}
	\Phi(v,v_1)=0\\
	\vdots\\
	\Phi(v,v_m)=0
	\end{cases}\) \(\Leftrightarrow\) \(\begin{cases}
	a_1\Phi(v_1,v_1)+\dots+a_n\Phi(v_n,v_1)=0\\
	\vdots\\
	a_1\Phi(v_1,v_m)+\dots+a_n\Phi(v_n,v_m)=0
	\end{cases}\)
	Dies ist ein lineares Gleichungssystem in den Unbestimmten \(a_1,\dots,a_n\) bestehend aus \(m\) Gleichungen.\\
	\ul{z.z.:} Der Rang der Koeffizientenmatrix ist der maximale, also \(m\).\\
	DOe Koeffizientenmatrix besteht aus den ersten \(m\) Zeilen von \(G_B(\Phi)^{tr}\). Wegen \(det(G_B(\Phi)^{tr})=det(G_B(\Phi))\neq 0\) sind diese \(m\) Zeilen linear unabhängig.
	\qed
\subsubsection{Korollar}
Ist \(\Phi:V\times V\rightarrow K\) eine nicht ausgeartete, symmetrische Bilinearform, so gilt: \((U^\bot)^\bot=U\) für jeden \(K\)-Untervektorraum \(U\) von \(V\).\\
\proof
Da \(\Phi\) symmetrisch ist, gilt \(U^\bot)^\bot\underset{TODO STERN KREIS}{\supset} U\). Da \(\Phi\) nicht ausgeartet ist, gilt \(dim_K(U^\bot)^\bot=dim_K(V)-dim_K(U^\bot)=dim_K(V)-(dim_K(V)-dim_K(U))=dim_K(U)\). Also ist TODO STERN KREIS eine Gleichheit.
\qed
\subsubsection{Beispiel}
(a) Sei \(K=\mathbb{R}\) und \(\Phi:\underset{((a_1,a_2,a_3),(b_1,b_2,b_3))\mapsto a_1b_2+a_2b_2+a_3+b_3}{\mathbb{R}^2\times \mathbb{R}^2\rightarrow \mathbb{R}}\) die Standardbilinearform. Für eine Gerade \(G=\mathbb{R}\cdot (a,b)\) durch 0 mit \((a,b)\neq (0,0)\) gilt \(G^\bot=\mathbb{R}\cdot (-b,a)\) und \(dim_\mathbb{R}(G)=dim_\mathbb{R}(G^\bot)=1\).
(b) Sei \(K=\mathbb{R}\) und \(V=\mathbb{R}^3\) und \(\Phi:\mathbb{R}^3\times\mathbb{R}^3\rightarrow \mathbb{R}\) die Standardbilinearform.\\
Ist \(G=\mathbb{R}\cdot (a_1,a_2,a_3)\) mit \((a_1,a_2,a_3)\neq (0,0,0)\) eine Gerade durch \(0\), so gilt: \(G^\bot=\{(b_1,b_2,b_3)\in\mathbb{R}^3|a_1b_1+a_2b_2+a_3b_3=0\}=<(-a_2,a_1,0),(0,-a_3,a_2),(-a_3,0,a_1)>\).\\
Falls \(a_1\neq0\), so gilt \(G^\bot=<(-\frac{a_2}{a_1},1,0),(-\frac{a_3}{a_1},0,1)>\)\\
\(dim_\mathbb{R}(G^\bot)=2=dim\mathbb{R}(\mathbb{R}^3)-dim_\mathbb{R}(G)\)\\
\ul{Probleme:}
(1) Es kann ein \(v\in V\backslash\{0\}\) geben mit \(\Phi(v,v)=0\).
(2) Es kann \(U\cap U^\bot\neq \{0\}\).
\subsection{Skalarprodukte (vgl. Buch S. 288-299)}
Im Folgenden sei \(K=\mathbb{R}\). Sei \(V\) ein (endlich-dimensionaler) \ul{reeller Vektorraum}, d.h. ein \(\mathbb{R}\)-Vektorraum ud sei \(n=dim_K(V)\).
\subsubsection{Definition}
(a) Eine Bilinearform \(\Phi:V\times V\rightarrow \mathbb{R}\) heißt \ul{positiv definit}, wenn gilt: \(\begin{cases}
\Phi(v,v)\geq 0\text{ für alle }v\in V\\
\Phi(v,v)=0 \Rightarrow v=0
\end{cases}\).
(b) Ein \ul{Skalarprodukt} auf \(V\) ist eine symmetrische, positiv definite Bilinearform \(\Phi:V\times V\rightarrow \mathbb{R}\).
(c) Ein \(\mathbb{R}\)-Vektorraum zusammen mit einem Skalarprodukt heißt ein \ul{euklidischer Vektorraum}.
\subsubsection{Bemerkung}
Ein Skalarprodukt ist nicht ausgeartet: Ist \(v\in V\) mit \(v\bot_\Phi V\) so folgt \(\Phi(v,v)=0\) und somit \(v=0\). Ein euklidischer Vektorraum enthält keine \ul{isotropen} Vektoren \(\neq 0\) (also \(\Phi(v,v)=0\Rightarrow v=0\))
\subsubsection{Beispiel}
Die Standardbilinearform \(\underset{((a_1\dots a_n),(b_1\dots b_n))\mapsto a_1b_1+\dots a_nb_n}{\Phi:\mathbb{R}^n\times \mathbb{R}^n\rightarrow \mathbb{R}}\) ist ein Skalarprodukt:\\
\(\Phi((a_1\dots a_n),(a_1\dots a_n))=a_1^2+\dots+a_n^2\geq 0\) und \(a_1^2+\dots+a_n^2=0\Rightarrow a_1=\dots=a_n=0\).\\
Es heißt auch das \ul{Standardskalarprodukt}. Wir schreiben auch \(<v,w>\) statt \(\Phi(v,w)\).\\
\ul{Fragen:} (1) Gibt es weitere Skalarprodukte auf \(\mathbb{R}^n\)?
(2) Wie kann man anhand von \(G_B(\Phi)\) erkennen, ob \(\Phi\) positiv definiert ist?
\subsubsection{Definition}
Sei \(V\) ein reeller Vektorraum.
(a) Eine \ul{Norm} auf \(V\) ist eine Abbildung \(\norm{\cdot}:V\rightarrow \mathbb{R}\) mit folgenden Eigenschaften:
(1) \(\norm{v}\geq 0\) und aus \(\norm{v}=0\) folgt \(v=0\) für alle \(v\in V\)
(2) Für \(a\in \mathbb{R}\) gilt \(\norm{a\cdot v}=\abs{a}\cdot \norm{v}\) für alle \(v\in V\)
(3) \(\norm{v+w}\leq \norm{v}+\norm{w}\) für alle \(v,w\in V\) (Dreiecksungleichung)
(b) Ein reeller Vektorraum mit einer Norm heißt ein \ul{normierter Vektorraum}.
\subsubsection{Definition}
Sei \((V,\Phi)\) ein euklidischer Vektorraum. Dann heißt \(\norm{\cdot}_\Phi:\underset{v\mapsto \sqrt{\Phi(V,V)}}{V\rightarrow \mathbb{R}}\) die zu \(\Phi\) \ul{assoziierte Norm}.
(b) Die zum Standardskalarprodukt auf \(\mathbb{R}^n\) assoziierte Norm heißt die \ul{euklidische Norm} auf \(\mathbb{R}^n\).
\subsubsection{Satz}
Sei \(V\) ein reeller Vektorraum und \(\Phi:V\times V\rightarrow \mathbb{R}\) ein Skalarprodukt auf \(V\).
(a) (Cauchy-Schwarzsche Ungleichung) \(\abs{\Phi(v,w)}\leq \norm{v}_\Phi\cdot \norm{w}_\Phi\) für alle \(v,w\in V\).
(b) Die zu \(\Phi\) assoziierte Norm \(\norm{\cdot}_\Phi\) ist eine Norm auf \(V\). Insbesondere gilt: \(\norm{v+w}\leq \norm{v}_\Phi+\norm{w}_\Phi\) für \(v,w\in V\).\\
\proof
"(a)" Für \(w=0\) sind beide Seiten gleich \(0\). Sei also \(w\neq 0\). Für \(a\in\mathbb{R}\) gilt \(\Phi(v-aw,v-aw)=\Phi(v,v)-a\cdot \Phi(v,w)-a\cdot \Phi(w,v)+a^2\cdot \Phi(w,w)=\Phi(v,v)-2a\cdot \Phi(v,w)+a^2\phi(w,w)\geq 0\). Wegen \(w\neq 0\) gilt \(\Phi(w,w)>0\) und wir können \(a=\frac{\Phi(v,w)}{\Phi(w,w)}\) wählen.\\
Dann folgt: \(\Phi(v,v)=\frac{2\Phi(v,w)^2}{\Phi(w,w)}+\frac{\Phi(v,w)^2}{\Phi(w,w)^2}\cdot \Phi(w,w)=\Phi(v,v)-\frac{\Phi(v,w)^2}{\Phi(w,w)}\geq 0\Rightarrow \Phi(v,v)\Phi(w,w)\geq \Phi(v,w)^2\) und da beide Seiten positiv sind, folgt \(\abs{\Phi(v,w)}\leq \sqrt{\Phi(v,v)}\sqrt{\Phi(w,w)}=\norm{v}_\Phi\cdot \norm{w}_\Phi\).
"(b)" Offenbar gilt \(\norm{v}_\Phi\geq 0\) und \(\norm{v}_\Phi=\sqrt{\Phi(v,v)}=0\Rightarrow\Phi(v,v)=0\Rightarrow v=0\).\\
Ferner gilt für \(a\in\mathbb{R}\) und \(v\in V\) die Gleichung \(\norm{av}_\Phi=\sqrt{\Phi(av,av)}=\sqrt{a^2\cdot \Phi(v,v)}=\abs{a}\cdot \sqrt{\Phi(v,v)}=\abs{a}\cdot \norm{v}_\Phi\).\\
Für \(v,w\in V\) gilt:\\
\(\norm{v+w}_\Phi^2=\Phi(v+w,v+w)=\Phi(v+v)+2\cdot \Phi(v,w)+\Phi(w,w)\leq \norm{v}_\Phi^2+\norm{w}_\Phi^2+2\abs{\Phi(v,w)}\underset{\text{c.s.}}{\leq}\norm{v}_\Phi^2+\norm{w}_\Phi^2+2\norm{v}_\Phi\cdot \norm{w}_\Phi=(\norm{v}_\Phi+\norm{w}_\Phi)^2\).\\
Da beide Seiten positiv sind, folgt \(\norm{v+w}_\Phi\leq \norm{v}_\Phi+\norm{w}_\Phi\)
\qed
\subsubsection{Definition}
Für alle \(v,w\in V\backslash\{0\}\) gilt: \(\frac{\abs{\Phi(v,w)}}{\norm{v}_\Phi\cdot \norm{w}_\Phi}\leq 1\), also \(-1\leq \frac{\Phi(v,w)}{\norm{v}_\Phi\cdot \norm{w}_\Phi}\leq 1\).\\
Damit ist der \ul{Winkel} \(\alpha\in[0,\pi[\) zwischen \(v\) und \(w\) eindeutig definiert durch \(cos(\alpha)=\frac{\Phi(v,w)}{\norm{v}_\Phi\cdot \norm{w}_\Phi}\)
\subsubsection{Bemerkung}
Mit Def. 26.7, angewandt auf das Standardskalarprodukt in \(\mathbb{R}^2\) oder \(\mathbb{R}^3\) kann man alle üblichen Sätze der euklidischen Geometrie beweisen, z.B. Sinussatz, Kosinussatz, Fasskreisbogen,\dots
\subsubsection{Definition}
Sei \((V,\Phi)\) ein euklidischer Vektorraum.
(a) Eine Menge \(M\) von Vektoren aus \(V\) heißt \ul{paarweise orthogonal}, wenn für \(v,w\in M\) mit \(v\neq w\) gilt \(\Phi(v,w)=0\).
(b) Eine paarweise orthogonale Menge \(M\subseteq V\) heißt \ul{orthonormal}, wenn für \(v\in M\) gilt \(\norm{v}_\Phi=1\).
(c) Eine Basis \(B\) von \(V\) heißt \ul{Orthogonalbasis} (OGB), wenn sie aus paarweise orthogonalen Vektoren besteht.
(d) Eine OGB von \(V\) heißt eine \ul{Orthonormalbasis} (ONB) von \(V\), wenn die Vektoren orthonormal sind.
\subsubsection{Bemerkung}
Ist \(B=\{v_1,\dots,v_n\}\) eine OGB von \(V\), so ist \(\tilde{B}=\{\frac{v_1}{\norm{v_1}_\Phi},\dots,\frac{v_n}{\norm{v_n}_\Phi}\}\) eine ONB von \(V\). Der Übergang von \(B\) zu \(\tilde{B}\) heißt \ul{Normieren}.
\subsubsection{Satz (Das Schmidtsche Orthogonalisierungsverfahren)}
Sei \((V,\Phi)\) ein euklidischer Vektorraum und \(B=\{v_1,\dots,v_n\}\) eine Basis von \(V\). Die folgenden Instruktionen definieren einen Algorithmus, der eine ONB \(C\) von \(V\) berechnet:\\
(1) Setze \(w_1=\frac{v_1}{\norm{v_1}}\)
(2) Für \(i=2,3,\dots,n\) berechne der Reihe nach \(\tilde{v_i}=\Phi(v_i,w_1)\cdot w_1+\dots+\Phi(v_i,w_{i-1})\cdot w_{i-1}\) und \(w_i=\frac{v_i-\tilde{v_i}}{\norm{v_i-\tilde{v_i}}}\)
(3) Gib \(C=\{w_1,\dots,w_n\}\) aus und stoppe.\\
\proof
\ul{Endlichkeit:} klar\\
\ul{Korrektheit:} Wir schließen mit Induktion nach i und zeigen, dass \(\{w_1,\dots,w_i\}\) orthonormal ist.\\
\ul{\(i=1\):} \(\norm{w_1}=\norm{\frac{v_1}{\norm{v_1}}}=\frac{\norm{v_1}}{\norm{v_1}}=1\).\\
\ul{\(i>1\):} Nach Konstruktion gilt \(w_i=\frac{v_i-\tilde{v_i}}{\norm{v_i-\tilde{v_i}}}\in  <v_i,w_1,\dots,w_{i-1}>\underset{\text{Induktion}}{=}<v_1,\dots,v_i>\) und es gilt \(v_i\notin <v_1,\dots,v_{i-1}>=<w_1,\dots,w_{i-1}>\). Also folgt \(v_i\neq \tilde{v_i}\) und somit \(\norm{v_i-\tilde{v_i}}\neq 0\).\\
	Für \(j=1,\dots,i-1\) gilt\\
	\(\Phi(w_j,w_i)=\frac{1}{\norm{v_i-\tilde{v_i}}}\Phi(v_i-\tilde{v_i},w_j)=\frac{1}{\norm{v_i-\tilde{v_i}}}\cdot \left[\Phi(v_i,w_j)-\Phi(\Phi(v_i,w_1)\cdot w_1,w_j)-\dots-\Phi(\Phi(v_i,w_{i-1})w_{i-1},w_j)\right]\)\\
	\(\frac{1}{\norm{v_i-\tilde{v_i}}}\left[\Phi(v_i,w_j)-\Phi(v_i,w_1)\cdot\underbrace{\Phi(w_1,w_j)}_{=0}-\dots-\Phi(w_i,w_{i-1})\cdot \underbrace{\Phi(w_{i-1},w_j)}_{=0}\right]=\frac{1}{\norm{v_i-\tilde{v_i}}}\cdot\left[\Phi(v_i,w_j)-\Phi(v_i,w_j)\cdot 1\right]=0\).\\
	Somit folgt \(w_i\bot <w_1,\dots,w_{i-1}>\) und offenbar gilt \(\norm{w_i}=1\).
	\qed
	\subsubsection{Beispiel}
	Sei \(V=\mathbb{R}^2\) und \(\Phi\) das Standardskalarprodukt. Ferner sei \(B=\{v_1,v_2\}\) mit \(v_1=(1,1)\) und \(v_2=(0,3)\).
	(1) \(w_1=\frac{v_1}{\norm{v_1}}=(\frac{1}{sqrt{2}},\frac{1}{sqrt{2}})\).
	(2) \(\tilde{v_2}=\Phi(v_2,w_1)\cdot w_1=\Phi((0,3),(\frac{1}{sqrt{2}},\frac{1}{sqrt{2}}))\cdot (\frac{1}{sqrt{2}},\frac{1}{sqrt{2}})=(\frac{3}{2},frac{3}{2})\).\\
	\(w_2=\frac{v_2-\tilde{v_2}}{\norm{v_2-\tilde{v_2}}}=\frac{(\frac{3}{2},\frac{3}{2})}{\norm{(\frac{3}{2},\frac{3}{2})}}=\frac{(-\frac{3}{2},\frac{3}{2})}{\frac{3}{\sqrt{2}}}=(-\frac{\sqrt{2}}{2},\frac{\sqrt{2}}{2})\).\\
	Also ist \(\tilde{B}=\{(\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}),(-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}})\}\) eine ONB von \(\mathbb{R}^2\).
	\subsubsection{Korollar}
	Ist \(M=\{v_1,\dots,v_k\}\) eine orthogonale Menge von Vektoren in \(V\), so kann man \(M\) zu einer ONB \(B=\{v_1,\dots,v_k,v_{k+1},\dots,v_n\}\) von \(V\) ergänzen.\\
	\proof
	Ergänze \(\{v_1,\dots,v_k\}\) durch \(\{w_{k+1},\dots,w_n\}\) zu einer Basis von \(V\) und wende dann Satz 26.11 an.
	\qed
	\subsubsection{Definition}
	Sei \((V,\Phi)\) ein euklidischer Vektorraum und seien \(U,W\) zwei Untervektorräume von \(V\). Gilt \(V=U\oplus W\) und \(U\bot_\Phi W\), so heißt \(V\) die \ul{orthogonale direkte Summe} von \(U\) und \(W\).\\
	\ul{Schreibweise:} \(V=U\oplus W\) TODOOPLUS NUR OBEN STRICh
	\subsubsection{Satz}
	Seu \((V,\Phi)\) ein euklidischer Vektorraum und \(U\subseteq V\) ein Untervektorraum.\\
	Dann gilt \(V=U\obot U^\bot\) und für alle \(W\subseteq V\) mit \(V=U\oplus W\) gilt \(W=U^\bot\). In diesem Fall heißt \(U^\bot\) das \ul{orthogonale Komplement} von \(U\).\\
	\proof
	Wegen der Dimensionsformel ist nur \(U\cap U^\bot=\{0\}\) zu zeigen. Für \(v\in U\cap U^\bot\) gilt \(\Phi(v,v)=0\Rightarrow v=0\).
	\qed
	\subsubsection{Bemerkung}
	(a) In \(V=\mathbb{R}^2\) betrachte \(v=(a_1,a_2)\) und \(w=(b_1,b_2)\). Dann ist die Fläche des von \(v und w\) aufgespannten Parallelogramms gegeben durch \(Vol(v,w)=\abs{a_1b_2-a_2b_1}=\abs{det\begin{pmatrix}
		a_1 & b_1\\
		a_2 & b_2
		\end{pmatrix}}\).
	(b) In \(V=\mathbb{R}^3\) betrachte \(v=(a_1,a_2,a_3),w=(b_1,b_2,b_3),u=(c_1,c_2,c_3)\). Dann ist das Volumen des von \(v,w,u\) aufgespannten \ul{Spats} (\ul{Parallelepipeds}) gegeben durch \(Vol(v,w,u)=\abs{det\underbrace{\begin{pmatrix}
			a_1 & b_1 & c_1\\
			a_2 & b_2 & c_2\\
			a_3 & b_3 & c_3
			\end{pmatrix}}_{A}}=\abs{det(A)}\)\\
		Sei \(B=(v,w,u)\) eine Basis von \(\mathbb{R}^3\).\\
		Die Gramsche Matrix des Standardskalarprodukts bzgl. der Basis \(B\) ist \(G_B(\Phi)=A^{tr}G_\xi(\Phi)A=A^{tr}A\) und es folgt \(det(G_B(\Phi))=det(A^{tr}A)=det(A^{tr})det(A)=det(A)^2\geq 0\). Dies liefert \(Vol(v,w,u)=\sqrt{det(G_B(\Phi))}\).
		\subsubsection{Definition}
		Sei \(V\) ein reeller Vektorraum und \(\Phi:V\times V\rightarrow \mathbb{R}\) eine Bilinearform auf \(V\). Ist \(B=(v_1,\dots,v_m)\) ein Tupel von Vektoren aus \(V\) mit \(G_B(\Phi)=(\Phi(v_i,v_j))_{i,j}\in Mat_m(\mathbb{R})\), so heißt \(G(v_1,\dots,v_m)=det(G_B(\Phi))\) die \ul{Gramsche Determinante} von \(\Phi\) bzgl. \(B\).
		\subsubsection{Satz}
		Sei \((V,\Phi)\) ein euklidischer Vektorraum und \(B=(v_1,\dots,v_n)\) ein Tupel von Vektoren aus \(V\).
		(a) Die Gramsche Determinante erfüllt \(G(v_1,\dots,v_n)=det(\Phi(v_i,v_j))_{i,j}\geq 0\).
		(b) Es gilt: \(G(v_1,\dots,v_n)=0\Leftrightarrow \{v_1,\dots,v_n\}\) linear abhängig.\\
		\proof
		"(a)" Sei \(C=(w_1,\dots,w_n)\) eine ONB von \(V\). Für \(i=1,\dots,m\) schreibe \(v_i=a_{i1}w_1+\dots+a_{im}w_m\) mit \(a_{ij}\in \mathbb{R}\).
		Setze \(A=(a_{ij})\in Mat_{m,n}(\mathbb{R})\). Betrachte den \ul{Fall \(m\leq n\):} Wähle Vektoren \(v_{m+1},\dots,v_n\) von \(V\), die Teil einer ONB von \(<v_1,\dots,v_n>^\bot\) sind.\\
Betrachte \(\tilde{A}=\begin{pmatrix}
A\\e_{m+1}\\\vdots\\e_n
\end{pmatrix}=TODO MATRICES\in Mat_n(\mathbb{R})\) und erhalte \(\tilde{A}\tilde{A}^{tr}=TODO MATRICES\) mit \(A'=A_2,A''=A_2^{tr}\) für \(A=\underset{\text{quadratisch}}{(A_1|A_2)}\). Es folgt: \(det(AA^{tr})=det(\tilde{A}\tilde{A}^{tr})=det(\tilde{A})\cdot det(\tilde{A}^{tr})=det(\tilde{A})^2\geq 0\). Beachte \(\Phi(v_i,v_j)=0\) für \(i\leq i\leq n\). Dies liefert \(A'=0\) und damit \circled{\(*\)}. Nun folgt die Behauptung aus \(G(v_1,\dots,v_m)=det\begin{pmatrix}
\Phi(v_1,v_1),\dots,\Phi(v_1,v_m)\\
\vdots\\
\Phi(v_m,v_1),\dots,\Phi(v_m,v_n)
\end{pmatrix}=det(AA^{tr})\geq 0\).
"(b)" Sind \(v_1,\dots,v_m\) linear abhängig, so sind die Zeilen von \(A\), bzw. \(\tilde{A}\) linear abhängig und es folgt \(G(v_1,\dots,v_n)=det(\tilde{A})^2=0\). Umgekehrt gilt:\\
\(G(v_1,\dots,v_m)=0\Rightarrow det(\tilde{A})^2=0\Rightarrow det(\tilde{A})=0\Rightarrow \{v_1,\dots,v_m\}\) linear abhängig.
\qed
\subsubsection{Definition}
Sei \((V,\Phi)\) ein euklidischer Vektorraum und \(B=(v_1,\dots,v_n)\) ein Basistupel von \(V\). Dann heißt \(Vol(v_1,\dots,v_n)=\sqrt{G(v_1,\dots,v_n)}\) das \ul{n-dimensionale Volumen} des von \(\{v_1,\dots,v_n\}\) aufgespannten Parallelepipeds bzgl. \(\Phi\).
\end{document}





























